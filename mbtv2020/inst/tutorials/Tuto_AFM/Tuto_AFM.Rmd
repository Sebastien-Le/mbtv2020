---
title: "AFM avec FactoMineR"
output: learnr::tutorial
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(FactoMineR)
knitr::opts_chunk$set(echo = FALSE)
data("wine")
wine<-wine[,-c(1,2,30,31)]
res <- MFA(wine, group=c(5,3,10,9), type=c(rep("s",4)),
           ncp=5, name.group=c("olf","vis","olfag","gust"),graph = FALSE)

wine1<-wine[,1:5]
wine2<-wine[,6:8]
wine3<-wine[,9:18]
wine4<-wine[,19:27]

resg1<-PCA(wine1,graph = FALSE)
resg2<-PCA(wine2,graph = FALSE)
resg3<-PCA(wine3,graph = FALSE)
resg4<-PCA(wine4,graph = FALSE)

lambda1_1<-resg1$eig
lambda1_2<-resg2$eig
lambda1_3<-resg3$eig
lambda1_4<-resg4$eig
```

## Introduction 

Nous allons voir en quoi une AFM peut être vu comme une ACP pondérée. Pour cela nous allons d'abord rélaliser une AFM, puis une ACP pondérée. Pour finir nous regarderons et comparerons les résultats. Pour ce tutoriel nous utiliserons le jeu de données `wine` qui correspond à un ensemble de vin décrit par différentes variables pouvant être rangée en groupes correspondant à différents sens, les variables pouvant être utilisées comme supplémentaires ont été retirées.

```{r heac,echo=TRUE}
head(wine)
```

## Réalisation d'une AFM

Pour utiliser la fonction `MFA` du package `SensoMineR` sur ce jeu de donnée, nous allons utiliser les paramètres: *base, group, type et name.group*.   
Le paramètre ***base*** est le dataframe sur lequel on souhaite effectuer la MFA.  
Le paramètre ***group*** fonctionne d'une manière assez particulière, c'est un vecteur contenant les différents nombres de variables de chaque groupe de l'AFM en partant de la première jusqu'à la dernière. Il est donc nécessaire d'utiliser la fonction `MFA`sur un dataframe ordonné comme c'est le cas ici.  
Le paramètre ***type*** indique le type des groupes "c" ou "s" pour les groupes composés de variables quantitatives ("s" pour les variables réduites), "n" pour les qualitatives et "f" pour les fréquences.  
Finalement ***name.group*** est un vecteur avec le nom donné aux différents groupes.  
La fonction MFA contient d'autre paramètre que vous pouvez aller voir avec `?MFA`.

Les groupes sont composés de la manière suivante, les 5 premières variables appartiennent au groupe *olfactif*, les 3 suivantes au groupe *visuel*, les 10 d'après sont du group *olfag*, enfin les 9 dernières appartiennent au groupe *gustatif*.
Tous ses groupes sont composés de variables réduites.

A vous de réaliser l'AFM correspondante:
```{r MFA, exercise=TRUE}
res <- MFA(wine, group=c(), type=c(),
           ncp=5, name.group=c("olf","vis","olfag","gust"),graph = FALSE
res$ind$coord
```

```{r MFA-hint,eval=FALSE}
res <- MFA(wine, group=c(5,3,10,9), type=c(rep("s",4)),
           ncp=5, name.group=c("olf","vis","olfag","gust"),graph = FALSE
res$ind$coord
```

## Réalisation d'une ACP pondérée

Le concept est de realiser en premier une ACP par groupe, afin de recuperer les valeurs propres des premiers axes qui serviront à effectuer la pondération des variables.  

**1** Séparer les groupes:

```{r sep, exercise=TRUE}
wine1<-wine[,1:]
wine2<-wine[,:]
wine3<-wine[,:]
wine4<-wine[,:27]
```

**2** Effectuer une ACP par groupe:
```{r acp, exercise=TRUE}
resg1<-PCA(wine1,graph = FALSE)
resg2<-PCA(wine2,graph = FALSE)
resg3<-PCA(wine3,graph = FALSE)
resg4<-PCA(wine4,graph = FALSE)
```

**3** Récupérer la première valeur propre $\lambda_1$ de chaque axe :

```{r eig, echo=TRUE,include=TRUE}
lambda1_1<-resg1$eig[1]
lambda1_2<-resg2$eig[1]
lambda1_3<-resg3$eig[1]
lambda1_4<-resg4$eig[1]
```

Afin de ne pas donner trop d'importance à un groupe, l'idée est de donner aux variables de chaque groupe un poids qui correspond à 1/$\lambda1$ de chaque groupe. Pour cela on va isoler dans des vecteurs les poids qu'on va assigner au différentes variables puis on va les rassembler en 1 seul vecteur qui sera utilisé comme le paramètre `col.w` de l'ACP. L'utilisation de la fonction `rep` est très utile dans ce type de situation (`?rep` pour plus d'informations). 
```{r ponde, exercise=TRUE, exercise.setup="eig"}
eig_1<-
eig_2<-
eig_3<-
eig_4<-
print(eig_1,eig_2,eig_3,eig_4)
```

```{r ponde-hint,eval=FALSE}
eig_1<-rep(1,5)/lambda1_1
eig_2<-rep(1,3)/lambda1_2
eig_3<-rep(1,10)/lambda1_3
eig_4<-rep(1,9)/lambda1_4
```

```{r eig2, echo=FALSE}
eig_1<-rep(1,5)/lambda1_1
eig_2<-rep(1,3)/lambda1_2
eig_3<-rep(1,10)/lambda1_3
eig_4<-rep(1,9)/lambda1_4
```

**4** Construire le vecteur de poid:
```{r ponde2,exercise=TRUE,exercise.setup="eig2"}
ponde<-
```

```{r ponde2-hint,eval=FALSE}
ponde<-c(ponde,eig_1,eig_2,eig_3,eig_4)
```

Nous pouvons maintenant effectué une ACP sur la table `wine` entière avec comme vecteur de poid, notre vecteur `ponde`. En regardant les coordonnées des individus de cette ACP on remarque que nous avons retrouvé les mêmes que celle de l'ACM.
```{r set,echo=FALSE}
eig_1<-rep(1,5)/lambda1_1
eig_2<-rep(1,3)/lambda1_2
eig_3<-rep(1,10)/lambda1_3
eig_4<-rep(1,9)/lambda1_4

ponde=c()
ponde=c(ponde,eig_1,eig_2,eig_3,eig_4)
```

**5** Réaliser l'ACP pondérée
```{r pcaponde, exercise=TRUE, exercise.setup="set",fig.keep="none"}
res.pca<-
```


```{r pcaponde-hint,eval=FALSE}
res.pca<-PCA(wine,col.w = ponde)
```

## Comparaison des résultats

```{r gr,echo=FALSE}
eig_1<-rep(1,5)/lambda1_1
eig_2<-rep(1,3)/lambda1_2
eig_3<-rep(1,10)/lambda1_3
eig_4<-rep(1,9)/lambda1_4

ponde=c()
ponde=c(ponde,eig_1,eig_2,eig_3,eig_4)

res.pca<-PCA(wine,col.w = ponde,graph = FALSE)
```

Observons d'abord les coordonnées moyennes des individus:
```{r ind, exercise.setup="gr",exercise=TRUE}
res.pca$ind$coord
res$ind$coord
```

Il n'y a pas que les coordonnées des individus qui sont semblables, ce sont tous les résultats communs qui sont identiques, les plus visuels étants les graphiques des individus ainsi que celui des variables:

```{r plot, exercise.setup="gr",exercise=TRUE}
plot.PCA(res.pca,choix = c("var"))
plot.MFA(res,choix = c("var"), graph.type = "ggplot")
```

```{r plot2, exercise.setup="gr",exercise=TRUE}
plot.PCA(res.pca,choix = c("ind"))
plot.MFA(res,choix = c("ind "), graph.type = "ggplot")
```
